 No meu trabalho de implementação da biblioteca Whispere em Python, eu decidi abordar a diferença entre os modelos multilíngues e os específicos para o inglês. Os modelos utilizados foram o Tiny, o Base, o Small e o Medium. Na primeira amostra, um trecho de uma série americana, com boa qualidade de áudio, baixo nível de ruídos, cadência normal de fala e alguns trechos cantados. O modelo em inglês saiu melhor no Base, Tiny e Medium, mas acabou se saindo pior no Small. Mas todos tiveram uma baixa taxa de erro no geral. Na segunda amostra, um discurso de Martin Luther King Jr. com alto nível de ruídos, um sotaque pesado e múltiplas vozes em alguns trechos. O modelo específico para inglês se saiu pior no Tiny e empatou com o multilíngue no Medium, mas acabou se saindo melhor no Base e no Small. Na terceira amostra, uma música com efeitos de voz, efeitos sonoros e palavras em línguas estrangeiras no início, o modelo em inglês se saiu melhor no Tiny, Base e Medium, e acabou saindo pouco pior no Small. No Medium teve uma grande discrepância, acabou tendo mais de 80% de erro, porque como tem palavras estrangeiras no início, ele acabou transcrevendo toda a música basicamente nessa língua estrangeira e não em inglês. Na quarta amostra, um vídeo de um canal do YouTube, apresentando um elevador antigo, com uma qualidade de áudio razoável e cadência de fala rápida, mas em inglês britânico. O modelo em inglês se saiu melhor no Tiny, Base, Small e no Medium, mas teve uma discrepância maior no Tiny. A quinta amostra, um compilado de vídeos do mesmo canal, onde o apresentador introduz vários lugares, portanto, o vídeo tem vários níveis de ruído, cadência de fala, volume, e tem vários nomes próprios e palavras estrangeiras. O modelo em inglês saiu melhor no Tiny, Base, mas pior no Small e no Medium. Na sexta amostra, um trecho de um programa britânico, com cadência normal de fala e trechos com múltiplas vozes. O modelo em inglês se saiu melhor apenas no Tiny, mas se saiu pior no Base, Small e no Medium. Em outro trecho do mesmo programa, com alto nível de ruído e com interrupção de fala, o modelo em inglês saiu melhor no Base e no Small, mas acabou saindo pior no Medium e no Tiny. Em outro trecho do mesmo programa, com ruído e cadência de fala normais, qualidade de áudio razoável, o modelo inglês acabou se saindo melhor em todos, mas com uma discrepância bem grande no Tiny. Em outro trecho do mesmo programa, com trechos com múltiplas vozes, mas ruído e cadência de fala normais, o modelo em inglês saiu melhor no Tiny, no Base e no Small, mas levemente pior no Medium. Na décima amostra, outro trecho com trechos com múltiplas vozes, mas ruído e cadência de fala normais, o modelo em inglês saiu melhor no Tiny, os dois empataram no Medium, mas acabou se saindo pior no Small e no Base. Na décima primeira amostra, o discurso de Winston Churchill, com alto nível de ruídos, um sotaque britânico bem pesado e nomes próprios, o modelo específico para inglês acabou saindo melhor no Tiny, no Base e no Medium, e empatou com o multilíngue no Small. Fazendo uma média das taxas de erro de cada modelo, em geral o modelo específico para inglês saiu melhor, mas no Medium acabou tendo uma discrepância por causa da amostra 3, que era uma amostra basicamente toda em inglês, mas com algumas palavras em outra língua. Portanto, fazendo uma média sem a amostra 3, a discrepância é menor e o Medium acaba sendo melhor do que o modelo específico para inglês, o multilíngue. Como o próprio GitHub da biblioteca aponta, a diferença dos dois modelos é bem menos perceptível no Medium, mas no Tiny, no Base, ocorre a maior diferença. E realmente o modelo inglês saiu bem melhor nesses tamanhos de modelo. A função que executa os modelos em cada amostra recebe como parâmetros uma lista com os modelos a serem executados, uma lista com o nome dos arquivos, que pode ser obtida pela função retorna_amostras, que por sua vez recebe como parâmetros o caminho da pasta de onde as amostras estão localizadas e dos formatos em que as amostras estão. Nesse caso, as amostras estão todas em MP3. O próximo parâmetro é o caminho da pasta das amostras, que também contém a transcrição de cada amostra, e o parâmetro opcional nome_resultados para dar um nome personalizado ao arquivo de resultados que a função gera. Primeiramente a função abre o arquivo de resultados e escreve um cabeçalho para cada amostra com as suas características. Para cada amostra também ele separa as palavras da transcrição oficial. Então, para cada modelo, ele executa o modelo, também registra o tempo que levou para executar o modelo, e escreve isso no arquivo de resultados. Então ele lê as palavras da transcrição oficial e compara com as palavras do modelo. Ao ler essas palavras ele retira qualquer caracter especial que tenha para garantir que ao fazer a comparação ele encontre as palavras nas duas listas. Então ele compara as palavras de cada lista de palavras e contabiliza as palavras corretas. Então ele escreve os resultados no arquivo de resultados. O arquivo de resultados contém as características de cada amostra, algumas características que retira do próprio arquivo de transcrição, e para cada modelo ele apresenta as métricas e a transcrição feita pelo modelo.